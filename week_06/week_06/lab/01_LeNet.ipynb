{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gKJRukyjTeTR"},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision"]},{"cell_type":"markdown","source":["# Implementing LeNet\n","\n","* In 1998, **LeNet** was among the first published convolutional neural networks to gather wide attention for its performance on computer vision tasks. In this lab session, you will use high-level PyTorch functionalities to implement the LeNet convolutional neural network.\n","\n","* You will use the [fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset, which is composed of labeled images of clothes and accessories.\n","\n","* The following function is used to load the dataset. You don't need to understand it for now.\n"],"metadata":{"id":"UxStOsDRlLy6"}},{"cell_type":"code","source":["# You don't need to understand this function for now.\n","def load_data_fashion_mnist(batch_size, resize=None):\n","    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n","    trans = [torchvision.transforms.ToTensor()]\n","    if resize:\n","        trans.insert(0, torchvision.transforms.Resize(resize))\n","    trans = torchvision.transforms.Compose(trans)\n","    mnist_train = torchvision.datasets.FashionMNIST(\n","        root=\"../data\", train=True, transform=trans, download=True)\n","    mnist_test = torchvision.datasets.FashionMNIST(\n","        root=\"../data\", train=False, transform=trans, download=True)\n","    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n","                            num_workers=2),\n","            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n","                            num_workers=2))"],"metadata":{"id":"Dg7DFApZlW95"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 256 # Defines the batch size\n","train_iter, test_iter = load_data_fashion_mnist(batch_size) # Loads the fashion MNIST dataset. `train_iter` and `test_iter` are `DataLoader` objects."],"metadata":{"id":"VKwzFubplY_E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X, y = next(iter(train_iter)) # Requests the first training batch\n","print(X.size()) # 256 images per batch. Each image is represented by a 1 x 28 x 28 tensor (number of channels x height x width). The images are grayscale, so there is a single channel.\n","print(y.size()) # 256 targets. Each target is a number between 0 and 9. The classification problem has 10 clases."],"metadata":{"id":"7eyZ9QkdlbXJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* The following code displays some images from the first training batch.\n"],"metadata":{"id":"vM8eOumLl_g_"}},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","\n","class_labels = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'boot'] # Pre-defined class labels\n","\n","for i in range(3):\n","    print(f'\\nImage {i} ({class_labels[int(y[i])]}):\\n') # Prints the index `i` and the label associated to the `i`-th image.\n","    cv2_imshow(X[i].numpy().transpose(1, 2, 0) * 255) # Converts and displays the `i`-th image in the batch."],"metadata":{"id":"ozCDXF68mBGH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Architecture\n","\n","* Your task is implementing the LeNet architecture described below in a class that inherits from `torch.nn.Module`.\n","\n","* The architecture receives a $1 \\times 28 \\times 28$ image and outputs a vector with $10$ elements.  The following layers are employed:\n","   * A convolutional layer with $6$ kernels, each a $1 \\times 5 \\times 5$ tensor, padding $2$, stride $1$, and a sigmoid activation function. **Output**: a $6 \\times 28 \\times 28$ tensor.\n","   * An average pooling layer with windows of size $2 \\times 2$ and stride $2$. **Output**: a $6 \\times 14 \\times 14$ tensor.\n","   * A convolutional layer with $16$ kernels, each a $6 \\times 5 \\times 5$ tensor, padding $0$, stride $1$, and a sigmoid activation function. **Output**: a $16 \\times 10 \\times 10$ tensor.\n","   * An average pooling layer with windows of size $2 \\times 2$ and stride $2$. **Output**: a $16 \\times 5 \\times 5$ tensor.\n","   * A fully connected layer wih $120$ units and a sigmoid activation function. The input is flatenned into a vector with $16 \\cdot 5 \\cdot 5 = 400$ elements. **Output**: a vector with $120$ elements.\n","   * A fully connected layer with $84$ units and a sigmoid activation function. **Output**: a vector with $84$ elements.\n","   * A fully connected layer with $10$ units and a softmax activation function **Output**: a vector with $10$ elements. *Note: the original LeNet used a so-called Gaussian activation layer, which is currently rarely used.*\n","\n","![LeNet-5 architecture.](https://drive.google.com/uc?export=view&id=1qht6z0oT0TGBYQl-aLiSRhBaPINi4rzE)\n","\n","* The class `torch.nn.Module` requires implementing the method `forward`, which should define the forward pass for a batch of images.\n","    * Because the batch size was set to $256$, a batch of images is represented by a $256 \\times 1 \\times 28 \\times 28$ tensor.\n","    * The method `forward` should compute the $256 \\times 10$ logits matrix $\\mathbf{O}$, not the prediction matrix $\\mathbf{\\hat{Y}} = \\text{softmax}(\\mathbf{O})$. In other words, the last fully connected layer does not need an (explicit) softmax activation function.\n","\n","* Use the code presented below as a starting point for implementing the convolutional neural network and fill the lines labeled with `TODO`.\n","\n","\n"],"metadata":{"id":"itIp5WK2FkGn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qb5aJZHBQ7TZ"},"outputs":[],"source":["class LeNet(torch.nn.Module):\n","    def __init__(self, num_outputs):\n","        super(LeNet, self).__init__()\n","        self.num_outputs = num_outputs\n","\n","        self.Sigmoid = None # TODO: Create a `torch.nn.Sigmoid` object to represent the sigmoid activation function\n","\n","        self.Convl1 = # TODO: Create a `torch.nn.Conv2d` object to represent the first convolutional layer\n","        self.Avg1 = # TODO: Create a `torch.nn.AvgPool2d` object to represent the first pooling layer\n","        self.Convl2 = # TODO: Create a `torch.nn.Conv2d` object to represent the second convolutional layer\n","        self.Avg2 = # TODO: Create a `torch.nn.AvgPool2d` object to represent the second pooling layer\n","\n","        self.Flatten = # TODO: Create a `torch.nn.Flatten` object to represent the operation that transforms a batch of images into a batch of vectors\n","        self.Linear1 = # TODO: Create a `torch.nn.Linear` object to represent the first fully connected layer\n","        self.Linear2 = # TODO: Create a `torch.nn.Linear` object to represent the second fully connected layer\n","        self.Linear3 = # TODO: Create a `torch.nn.Linear` object to represent the third fully connected layer\n","\n","    def forward(self, x):\n","        # TODO: Apply each `torch.nn.Module` create above to the batch of images `x`.\n","        # Hint: Don't forget to apply the sigmoid function after each convolutional/fully connected layer (except the last)\n","        return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLQCSd34TeTX"},"outputs":[],"source":["# Applies Xavier initialization if the `torch.nn.Module` is `torch.nn.Linear` or `torch.nn.Conv2d`\n","def init_weights(m):\n","    if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:\n","        torch.nn.init.xavier_uniform_(m.weight)\n","\n","num_outputs = 10\n","model = LeNet(num_outputs)\n","model.apply(init_weights) # Applies `init_weights` to every `torch.nn.Module` inside `model`"]},{"cell_type":"markdown","source":["## Loss function\n","\n","* The *convolutional neural network* defined above computes the logits matrix $\\mathbf{O}$, not the prediction matrix $\\mathbf{\\hat{Y}} = \\text{softmax}(\\mathbf{O})$.\n","\n","* This is because PyTorch provides a class called `CrossEntropyLoss` that implements the desired cross entropy loss but requires a logits matrix $\\mathbf{O}$ instead of the prediction matrix $\\mathbf{\\hat{Y}}$.\n","\n","* The class `CrossEntropyLoss` implements the cross entropy loss in a way that avoids numerical instabilities that would result from a naive implementation."],"metadata":{"id":"enMGpCPUnVpp"}},{"cell_type":"code","source":["loss = torch.nn.CrossEntropyLoss()"],"metadata":{"id":"ycyT2k8yndlD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Optimization Algorithm\n","\n","* We will employ minibatch stochastic gradient descent with a learning rate of $0.9$ as the optimization algorithm.\n","\n","* Because we implemented a subclass of `torch.nn.Module`, the model parameters can be accessed through the method `parameters`."],"metadata":{"id":"LT3SAqBknhsE"}},{"cell_type":"code","source":["lr = 0.9\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)"],"metadata":{"id":"MVho-LM7nlvF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation\n","\n","* Recall that the highest element of a logits vector determines which class will be predicted.\n","\n","* We can use this to compute the number of correct predictions per batch."],"metadata":{"id":"eFkOv_qjnuJ8"}},{"cell_type":"code","source":["def correct(logits, y):\n","    y_hat = logits.argmax(axis=1) # Finds the column with the highest value for each row of `logits`.\n","    return (y_hat == y).float().sum() # Computes the number of times that `y_hat` and `y` match.\n","\n","# Example: 1 correct classification,\n","y = torch.tensor([2, 1])\n","logits = torch.tensor([[0.1, 0.3, 0.6], [0.5, 0.2, 0.3]])\n","print(correct(logits, y))"],"metadata":{"id":"cKKl2JzsnwET"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* We can use the previous function to compute the accuracy of our model in a given dataset by accumulating the number of correct predictions across batches and then dividing that number by the number of examples in the dataset."],"metadata":{"id":"HP2mwthnnzF1"}},{"cell_type":"code","source":["def evaluate_metric(model, data_iter, metric):\n","    \"\"\"Compute the average `metric` of the model on a dataset.\"\"\"\n","    c = torch.tensor(0.)\n","    n = torch.tensor(0.)\n","    for X, y in data_iter:\n","        logits = model(X)\n","        c += metric(logits, y)\n","        n += len(y)\n","\n","    return c / n"],"metadata":{"id":"HjoPQnFgn0hC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'Training accuracy: {evaluate_metric(model, train_iter, correct)}. Testing accuracy: {evaluate_metric(model, test_iter, correct)}.')"],"metadata":{"id":"pAPDS76cn2Bh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training\n","\n","* The following code implements the training loop for the convolutional neural network.\n","\n","* The training/testing dataset accuracy is displayed after each epoch and stored for plotting.\n","\n","* **Important:** it is a methodological mistake to compute performance metrics on the *testing* dataset for the purposes of hyperparameter tuning. A *validation* dataset should be used for that purpose, even if it requires splitting the original training dataset into a training dataset and a validation dataset. The *test* dataset should only be used to evaluate the performance of the final set of hyperparameters, in order to assess generalization."],"metadata":{"id":"qdRoGih_n7Mc"}},{"cell_type":"code","source":["losses = [] # Stores the loss for each training batch\n","train_accs = [] # Stores the training accuracy after each epoch\n","test_accs = [] # Stores the testing accuracy after each epoch\n","\n","num_epochs = 20\n","for epoch in range(num_epochs):\n","    print(f'\\nEpoch {epoch + 1}/{num_epochs}.')\n","    for X, y in train_iter:\n","        logits = model(X) # Computes the logits for the batch of images `X`\n","\n","        l = loss(logits, y) # Computes the loss given the `logits` and the class vector `y`\n","        optimizer.zero_grad() # Zeroes the gradients stored in the model parameters\n","        l.backward() # Computes the gradient of the loss `l` with respect to the model parameters\n","\n","        optimizer.step() # Updates the model parameters based on the gradients stored inside them\n","\n","        losses.append(float(l)) # Stores the loss for this batch\n","\n","    with torch.no_grad(): # Computing performance metrics does not require gradients\n","        train_accs.append(evaluate_metric(model, train_iter, correct))\n","        test_accs.append(evaluate_metric(model, test_iter, correct))\n","        print(f'Training accuracy: {train_accs[-1]}. Testing accuracy: {test_accs[-1]}.') # Computes and displays training/testing dataset accuracy.\n","\n","plt.plot(losses) # Plots the loss for each training batch\n","plt.xlabel('Training batch')\n","plt.ylabel('Cross entropy loss')\n","plt.show()\n","\n","plt.plot(train_accs, label='Training accuracy')\n","plt.plot(test_accs, label='Testing accuracy')\n","plt.legend(loc='best')\n","plt.xlabel('Epoch')\n","plt.show()"],"metadata":{"id":"8Jp4ycDIn_X8"},"execution_count":null,"outputs":[]}],"metadata":{"celltoolbar":"Slideshow","colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}